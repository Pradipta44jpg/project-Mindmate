<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Project1 -- MindMate</title>

    <!-- Face API -->
    <script defer src="https://unpkg.com/face-api.js@0.22.2/dist/face-api.min.js"></script>

    <style>
        body {
            font-family: Arial, sans-serif;
            background: #f2f2f2;
            padding: 20px;
        }

        #chat-box {
            background: white;
            padding: 15px;
            height: 300px;
            overflow-y: auto;
            border-radius: 5px;
            margin-bottom: 10px;
        }

        input {
            width: 75%;
            padding: 10px;
        }

        button {
            padding: 10px;
            cursor: pointer;
        }

        #micBtn.listening {
            background-color: #ffcccc;
        }

        video {
            border-radius: 5px;
            margin-top: 10px;
        }
    </style>
</head>

<body>

<h2>MindMate ðŸ’™</h2>

<div id="chat-box"></div>

<input type="text" id="user-input" placeholder="Type how you feel..." />
<button onclick="sendMessage()">Send</button>

<br><br>

<button id="micBtn">ðŸŽ¤ Speak</button>
<p id="speechStatus"></p>

<h3>Camera Status</h3>
<video id="video" width="320" height="240" autoplay muted></video>
<p id="faceStatus">Initializing camera...</p>

<script>
/* ================== STATE VARIABLES ================== */
let facePresent = false;
let lastFaceState = false;

/* ================== HELPER FUNCTION ================== */
function addSystemMessage(message) {
    const chatBox = document.getElementById("chat-box");
    chatBox.innerHTML += `<p style="color:gray"><i>MindMate:</i> ${message}</p>`;
    chatBox.scrollTop = chatBox.scrollHeight;
}

/* ================== TEXT CHAT ================== */
async function sendMessage() {
    let text = document.getElementById("user-input").value.trim();
    if (!text) return;

    await sendToBackend(text, "text");
    document.getElementById("user-input").value = "";
}


async function sendToBackend(text, source = "text") {
    let chatBox = document.getElementById("chat-box");
    chatBox.innerHTML += `<p><b>You:</b> ${text}</p>`;

    try {
        let response = await fetch("http://127.0.0.1:5000/predict", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ 
                text: text,
                source: source 
            })
        });

        let data = await response.json();
        chatBox.innerHTML += `<p><b>MindMate:</b> ${data.reply}</p>`;
    } catch {
        chatBox.innerHTML += `<p style="color:red">Error connecting to server</p>`;
    }

    chatBox.scrollTop = chatBox.scrollHeight;
}

/* ================== SPEECH TO TEXT ================== */
const micBtn = document.getElementById("micBtn");
const statusText = document.getElementById("speechStatus");

const SpeechRecognition =
    window.SpeechRecognition || window.webkitSpeechRecognition;

if (SpeechRecognition) {
    const recognition = new SpeechRecognition();
    recognition.lang = "en-US";
    recognition.continuous = false;

    micBtn.onclick = () => {
        micBtn.classList.add("listening");
        statusText.innerText = "ðŸŽ¤ Listening...";
        recognition.start();
    };

    recognition.onresult = (event) => {
        const transcript = event.results[0][0].transcript;
        micBtn.classList.remove("listening");
        statusText.innerText = "You said: " + transcript;
        sendToBackend(transcript, "voice");

    };

    recognition.onend = () => {
        micBtn.classList.remove("listening");
    };
} else {
    statusText.innerText = "Speech recognition not supported.";
}

/* ================== CAMERA ================== */
const video = document.getElementById("video");
const faceStatus = document.getElementById("faceStatus");

async function startCamera() {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        faceStatus.innerText = "ðŸ“· Camera active";
        addSystemMessage("Iâ€™m here whenever youâ€™re ready ðŸ’™");
    } catch (error) {
        faceStatus.innerText = "âŒ Camera access denied";
        console.error(error);
    }
}

startCamera();

/* ================== FACE DETECTION ================== */
async function loadModels() {
    await faceapi.nets.tinyFaceDetector.loadFromUri(
        "https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights"
    );
    startFaceDetection();
}

async function startFaceDetection() {
    setInterval(async () => {
        if (!video.srcObject) return;

        const detections = await faceapi.detectAllFaces(
            video,
            new faceapi.TinyFaceDetectorOptions()
        );

        const facePresentNow = detections.length > 0;

        // Face appeared
        if (facePresentNow && !lastFaceState) {
            faceStatus.innerText = "ðŸ™‚ I see you. How are you feeling today?";
            addSystemMessage("ðŸ™‚ I see you. How are you feeling today?");
        }

        // Face disappeared
        if (!facePresentNow && lastFaceState) {
            faceStatus.innerText = "ðŸ‘€ Iâ€™ll be right here when you return.";
            addSystemMessage("ðŸ‘€ Iâ€™ll be right here when you return ðŸ’™");
        }

        lastFaceState = facePresentNow;

    }, 1500);
}
loadModels();
</script>

</body>
</html>
