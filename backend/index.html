<!DOCTYPE html>
<html>
<head>
    <title>Project1 -- MindMate</title>
    <script defer src="https://unpkg.com/face-api.js"></script>


    <style>
        body {
            font-family: Arial, sans-serif;
            background: #f2f2f2;
            padding: 20px;
        }

        #chat-box {
            background: white;
            padding: 15px;
            height: 300px;
            overflow-y: auto;
            border-radius: 5px;
            margin-bottom: 10px;
        }

        input {
            width: 75%;
            padding: 10px;
        }

        button {
            padding: 10px;
            cursor: pointer;
        }

        #micBtn.listening {
            background-color: #ffcccc;
        }

        video {
            border-radius: 5px;
            margin-top: 10px;
        }
    </style>

</head>

<body>

<h2>MindMate ðŸ’™</h2>

<div id="chat-box"></div>

<input type="text" id="user-input" placeholder="Type how you feel..." />
<button onclick="sendMessage()">Send</button>

<br><br>

<button id="micBtn">ðŸŽ¤ Speak</button>
<p id="speechStatus"></p>

<h3>Camera Status</h3>
<video id="video" width="320" height="240" autoplay muted></video>
<p id="faceStatus">Initializing camera...</p>

<script>
/* ------------------ CHAT HELPERS ------------------ */

function addSystemMessage(message) {
    let chatBox = document.getElementById("chat-box");
    chatBox.innerHTML += `<p style="color:gray"><i>MindMate:</i> ${message}</p>`;
    chatBox.scrollTop = chatBox.scrollHeight;
}

/* ------------------ TEXT CHAT ------------------ */

async function sendMessage() {
    let text = document.getElementById("user-input").value.trim();
    if (!text) return;

    await sendToBackend(text);
    document.getElementById("user-input").value = "";
}

async function sendToBackend(text) {
    let chatBox = document.getElementById("chat-box");
    chatBox.innerHTML += `<p><b>You:</b> ${text}</p>`;

    try {
        let response = await fetch("http://127.0.0.1:5000/predict", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ text })
        });

        let data = await response.json();
        chatBox.innerHTML += `<p><b>MindMate:</b> ${data.reply}</p>`;
    } catch {
        chatBox.innerHTML += `<p style="color:red">Error connecting to server</p>`;
    }

    chatBox.scrollTop = chatBox.scrollHeight;
}

/* ------------------ SPEECH TO TEXT ------------------ */

const micBtn = document.getElementById("micBtn");
const statusText = document.getElementById("speechStatus");

const SpeechRecognition =
    window.SpeechRecognition || window.webkitSpeechRecognition;

let recognition;

if (!SpeechRecognition) {
    statusText.innerText = "Speech recognition not supported.";
} else {
    recognition = new SpeechRecognition();
    recognition.lang = "en-US";
    recognition.continuous = false;
    recognition.interimResults = false;

    micBtn.onclick = () => {
        micBtn.disabled = true;
        micBtn.classList.add("listening");
        statusText.innerText = "ðŸŽ¤ Listening...";

        recognition.start();
    };

    recognition.onresult = (event) => {
        const transcript = event.results[0][0].transcript.trim();
        statusText.innerText = "You said: " + transcript;
        sendToBackend(transcript);
    };

    recognition.onerror = () => {
        statusText.innerText = "Speech error. Try again.";
    };

    recognition.onend = () => {
        micBtn.disabled = false;
        micBtn.classList.remove("listening");
    };
}

/* ------------------ CAMERA ------------------ */

const video = document.getElementById("video");
const faceStatus = document.getElementById("faceStatus");

let facePresent = false;
let lastFaceState = false;

async function startCamera() {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({
            video: true
        });
        video.srcObject = stream;
        faceStatus.innerText = "ðŸ“· Camera started.";
        addSystemMessage("Iâ€™m here whenever youâ€™re ready ðŸ’™");
    } catch (error) {
        faceStatus.innerText = "âŒ Camera access denied.";
        console.error(error);
    }
}

// Start camera when page loads
startCamera();

/* ------------------ BASIC FACE PRESENCE (SIMULATED) ------------------ */
/* Real face detection will be added later using ML / MediaPipe */

setInterval(() => {
    // For now we assume camera ON = face present
    facePresent = video.srcObject !== null;

    if (facePresent && !lastFaceState) {
        addSystemMessage("ðŸ™‚ I see you. How are you feeling today?");
    }

    if (!facePresent && lastFaceState) {
        addSystemMessage("ðŸ‘€ Iâ€™ll be right here when you return.");
    }

    lastFaceState = facePresent;
}, 3000);
async function loadFaceModels() {
    await faceapi.nets.tinyFaceDetector.loadFromUri(
        "https://cdn.jsdelivr.net/npm/face-api.js/models"
    );
}
loadFaceModels().then(() => {
    console.log("Face detection models loaded");
});
</script>

</body>
</html>


